Title,Offered by,Level,Rating,URL,Description,Skills
Microsoft Azure Data Scientist Associate (DP-100) Professional Certificate,Microsoft,Intermediate,4.5,https://in.coursera.org/professional-certificates/azure-data-scientist,"This Professional Certificate is intended for data scientists with existing knowledge of Python and machine learning frameworks like Scikit-Learn, PyTorch, and Tensorflow, who want to build and operate machine learning solutions in the cloud. This Professional Certificate teaches learners how to create end-to-end solutions in Microsoft Azure. They will learn how to manage Azure resources for machine learning; run experiments and train models; deploy and operationalize machine learning solutions; and implement responsible machine learning. They will also learn to use Azure Databricks to explore, prepare, and model data; and integrate Databricks machine learning processes with Azure Machine Learning.

This program consists of 5 courses to help prepare you to take the Exam DP-100: Designing and Implementing a Data Science Solution on Azure. The certification exam is an opportunity to prove knowledge and expertise operate machine learning solutions at cloud scale using Azure Machine Learning. This Professional Certificate teaches you to leverage your existing knowledge of Python and machine learning to manage data ingestion and preparation, model training and deployment, and machine learning solution monitoring in Microsoft Azure. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this program, you will be ready to take the DP-100: Designing and Implementing a Data Science Solution on Azure.","Manage Azure resources for machine learning Deploy and operationalize machine learning solutions Run experiments and train models Implement responsible machine learning Machine Learning Supervised Learning Regression Analysis 
regression Work with Data and Compute in Azure Machine Learning Use the Azure Machine Learning SDK to train a model Select models and protect sensitive data Orchestrate pipelines and deploy real-time machine learning services with Azure Machine Learning"
Machine Learning Specialization,Stanford University,Beginner,4.9,https://in.coursera.org/specializations/machine-learning-introduction,"The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. This beginner-friendly program will teach you the fundamentals of machine learning and how to use these techniques to build real-world AI applications. 

This Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.

This 3-course Specialization is an updated version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012. 

It provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)

By the end of this Specialization, you will have mastered key concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.",Decision Trees Artificial Neural Network Logistic Regression Recommender Systems Linear Regression Regularization to Avoid Overfitting Gradient Descent Supervised Learning Logistic Regression for Classification Xgboost Tensorflow Tree Ensembles
Machine Learning Engineering for Production (MLOps) Specialization,DeepLearning.AI,Advanced,4.7,https://in.coursera.org/browse/data-science/machine-learning,"Understanding machine learning and deep learning concepts is essential, but if you’re looking to build an effective AI career, you need production engineering capabilities as well. 

Effectively deploying machine learning models requires competencies more commonly found in technical fields such as software engineering and DevOps. Machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles. 

The Machine Learning Engineering for Production (MLOps) Specialization covers how to conceptualize, build, and maintain integrated systems that continuously operate in production. In striking contrast with standard machine learning modeling, production systems need to handle relentless evolving data. Moreover, the production system must run non-stop at the minimum cost while producing the maximum performance. In this Specialization, you will learn how to use well-established tools and methodologies for doing all of this effectively and efficiently.

In this Specialization, you will become familiar with the capabilities, challenges, and consequences of machine learning engineering in production. By the end, you will be ready to employ your new production-ready skills to participate in the development of leading-edge AI technology to solve real-world problems.",Managing Machine Learning Production Systems Deployment Pipelines Model Pipelines Data Pipelines Machine Learning Engineering for Production Human-level Performance (HLP) Concept Drift Model baseline Project Scoping and Design ML Deployment Challenges ML Metadata Convolutional Neural Network
Fundamentals of Machine Learning for Healthcare,Stanford University,Beginner,4.8,https://in.coursera.org/learn/fundamental-machine-learning-healthcare,"Machine learning and artificial intelligence hold the potential to transform healthcare and open up a world of incredible promise. But we will never realize the potential of these technologies unless all stakeholders have basic competencies in both healthcare and machine learning concepts and principles. 

This course will introduce the fundamental concepts and principles of machine learning as it applies to medicine and healthcare. We will explore machine learning approaches, medical use cases, metrics unique to healthcare, as well as best practices for designing, building, and evaluating machine learning applications in healthcare.

The course will empower those with non-engineering backgrounds in healthcare, health policy, pharmaceutical development, as well as data science with the knowledge to critically evaluate and use these technologies.",Machine learning Biostatistics Traditional computer programming Neural network architectures Clinical machine learning application
IBM Machine Learning Professional Certificate,IBM,Intermediate,4.6,https://in.coursera.org/professional-certificates/ibm-machine-learning,"Machine Learning is one of the most in-demand skills for jobs related to modern AI applications, a field in which hiring has grown 74% annually for the last four years (LinkedIn). This Professional Certificate from IBM is intended for anyone interested in developing skills and experience to pursue a career in Machine Learning and leverage the main types of Machine Learning: Unsupervised Learning, Supervised Learning, Deep Learning, and Reinforcement Learning. It also complements your learning with special topics.

This program consists of 6 courses providing you with solid theoretical understanding and considerable practice of the main algorithms, uses, and best practices related to Machine Learning . You will follow along and code your own projects using some of the most relevant open source frameworks and libraries and you will apply what you have learned in various courses by completing a final capstone project. 

Although it is recommended that you have some background in Python programming, statistics, and linear algebra, this intermediate series is suitable for anyone who has some computer skills, interest in leveraging data, and a passion for self-learning. We start small, provide a solid theoretical background and code-along labs and demos, and build up to more complex topics.  

In addition to earning a Professional Certificate from Coursera, you will also receive a digital Badge from IBM recognizing your proficiency in Machine Learning.   ",Artificial Intelligence (AI) Machine Learning Feature Engineering Statistical Hypothesis Testing Exploratory Data Analysis Regression Analysis Supervised Learning Linear Regression Ridge Regression Machine Learning (ML) Algorithms Decision Tree Ensemble Learning 
"Unsupervised Learning, Recommenders, Reinforcement Learning",Stanford University,Beginner,4.9,https://in.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning,"In the third course of the Machine Learning Specialization, you will:

• Use unsupervised learning techniques for unsupervised learning: including clustering and anomaly detection.
• Build recommender systems with a collaborative filtering approach and a content-based deep learning method.
• Build a deep reinforcement learning model.

The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. In this beginner-friendly program, you will learn the fundamentals of machine learning and how to use these techniques to build real-world AI applications. 

This Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.

This 3-course Specialization is an updated and expanded version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012. 

It provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)

By the end of this Specialization, you will have mastered key concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.",Collaborative Filtering Unsupervised Learning Recommender Systems Reinforcement Learning Anomaly Detection
Introduction to Machine Learning in Production,DeepLearning.AI,Advanced,4.8,https://in.coursera.org/learn/introduction-to-machine-learning-in-production,"In the first course of Machine Learning Engineering for Production Specialization, you will identify the various components and design an ML production system end-to-end: project scoping, data needs, modeling strategies, and deployment constraints and requirements; and learn how to establish a model baseline, address concept drift, and prototype the process for developing, deploying, and continuously improving a productionized ML application.

Understanding machine learning and deep learning concepts is essential, but if you’re looking to build an effective AI career, you need production engineering capabilities as well. Machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production-ready skills. 

Week 1: Overview of the ML Lifecycle and Deployment
Week 2: Selecting and Training a Model
Week 3: Data Definition and Baseline",Human-level Performance (HLP) Concept Drift Model baseline Project Scoping and Design ML Deployment Challenges 
Applied Machine Learning in Python,Michigan University,Intermediate,4.6,https://in.coursera.org/learn/python-machine-learning,"This course will introduce the learner to applied machine learning, focusing more on the techniques and methods than on the statistics behind these methods. The course will start with a discussion of how machine learning is different than descriptive statistics, and introduce the scikit learn toolkit through a tutorial. The issue of dimensionality of data will be discussed, and the task of clustering data, as well as evaluating those clusters, will be tackled. Supervised approaches for creating predictive models will be described, and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability (e.g. cross validation, overfitting). The course will end with a look at more advanced techniques, such as building ensembles, and practical limitations of predictive models. By the end of this course, students will be able to identify the difference between a supervised (classification) and unsupervised (clustering) technique, identify which technique they need to apply for a particular dataset and need, engineer features to meet that need, and write python code to carry out an analysis. 

This course should be taken after Introduction to Data Science in Python and Applied Plotting, Charting & Data Representation in Python and before Applied Text Mining in Python and Applied Social Analysis in Python.",Python Programming Machine Learning (ML) Algorithms Machine Learning Scikit-Learn
Getting Started with AWS Machine Learning,AWS,Intermediate,4.5,https://in.coursera.org/learn/aws-machine-learning,"Machine learning (ML) is one of the fastest growing areas in technology and a highly sought after skillset in today’s job market. The World Economic Forum states the growth of artificial intelligence (AI) could create 58 million net new jobs in the next few years, yet it’s estimated that currently there are 300,000 AI engineers worldwide, but millions are needed. This means there is a unique and immediate opportunity for you to get started with learning the essential ML concepts that are used to build AI applications – no matter what your skill levels are. Learning the foundations of ML now, will help you keep pace with this growth, expand your skills and even help advance your career. 

This course will teach you how to get started with AWS Machine Learning. Key topics include: Machine Learning on AWS, Computer Vision on AWS, and Natural Language Processing (NLP) on AWS. Each topic consists of several modules deep-diving into variety of ML concepts, AWS services as well as insights from experts to put the concepts into practice",Artificial Intelligence (AI) Machine Learning Amazon SageMaker Natural Language Processing (NLP) Computer Vision
DeepLearning.AI TensorFlow Developer Professional Certificate,DeepLearning.AI,Intermediate,4.7,https://in.coursera.org/professional-certificates/tensorflow-in-practice,"TensorFlow is one of the most in-demand and popular open-source deep learning frameworks available today. The DeepLearning.AI TensorFlow Developer Professional Certificate program teaches you applied machine learning skills with TensorFlow so you can build and train powerful models. 

In this hands-on, four-course Professional Certificate program, you’ll learn the necessary tools to build scalable AI-powered applications with TensorFlow. After finishing this program, you’ll be able to apply your new TensorFlow skills to a wide range of problems and projects. This program can help you prepare for the Google TensorFlow Certificate exam and bring you one step closer to achieving the Google TensorFlow Certificate.

Ready to deploy your models to the world? Learn how to go live with your models with the TensorFlow: Data and Deployment Specialization.

Looking to customize and build powerful real-world models for complex scenarios? Check out the TensorFlow: Advanced Techniques Specialization. ","Computer Vision Convolutional Neural Network Machine Learning 
Natural Language Processing Tensorflow Inductive Transfer Augmentation Dropouts 
Tokenization RNNs Forecasting Time Series"
IBM AI Engineering Professional Certificate,IBM,Intermediate,4.5,https://in.coursera.org/professional-certificates/ai-engineer,"Artificial intelligence (AI) is revolutionizing entire industries, changing the way companies across sectors leverage data to make decisions. To stay competitive, organizations need qualified AI engineers who use cutting-edge methods like machine learning algorithms and deep learning neural networks to provide data driven actionable intelligence for their businesses. This 6-course Professional Certificate is designed to equip you with the tools you need to succeed in your career as an AI or ML engineer.  

You’ll master fundamental concepts of machine learning and deep learning, including supervised and unsupervised learning, using programming languages like Python. You’ll apply popular machine learning and deep learning libraries such as SciPy, ScikitLearn, Keras, PyTorch, and Tensorflow to industry problems involving object recognition, computer vision, image and video processing, text analytics, natural language processing (NLP), recommender systems, and other types of classifiers.

Through hands-on projects, you’ll gain essential data science skills scaling machine learning algorithms on big data using Apache Spark. You’ll build, train, and deploy different types of deep architectures, including convolutional neural networks, recurrent networks, and autoencoders.

In addition to earning a Professional Certificate from Coursera, you will also receive a digital badge from IBM recognizing your proficiency in AI engineering.",SciPy and scikit-learn Machine Learning Regression Classification Hierarchical Clustering Deep Learning Artificial Neural Network Artificial Intelligence (AI) Keras Opencv Image Processing Computer Vision
Practical Decision-Making Using No-code ML on AWS,AWS,Beginner,Not available,https://in.coursera.org/learn/no-code-ml-aws,"In this course, you will discover how to solve business problems with machine learning, no coding required. You will explore Amazon SageMaker Canvas, a visual point-and-click interface that allows you to generate accurate ML predictions without requiring any machine learning experience or having to write a single line of code. At the end of the course, you will walk away understanding how to make better business decisions using no-code machine learning.",Business Analytics Artificial Intelligence (AI) AWS cloud No-Code Machine Learning Automated Machine Learning (AutoML)
Mathematics for Machine Learning Specialization,Imperial College London,Beginner,4.6,https://in.coursera.org/specializations/mathematics-machine-learning,"For a lot of higher level courses in Machine Learning and Data Science, you find you need to freshen up on the basics in mathematics - stuff you may have studied before in school or university, but which was taught in another context, or not very intuitively, such that you struggle to relate it to how it’s used in Computer Science. This specialization aims to bridge that gap, getting you up to speed in the underlying mathematics, building an intuitive understanding, and relating it to Machine Learning and Data Science.

In the first course on Linear Algebra we look at what linear algebra is and how it relates to data. Then we look through what vectors and matrices are and how to work with them.

The second course, Multivariate Calculus, builds on this to look at how to optimize fitting functions to get good fits to data. It starts from introductory calculus and then uses the matrices and vectors from the first course to look at data fitting.

The third course, Dimensionality Reduction with Principal Component Analysis, uses the mathematics from the first two courses to compress high-dimensional data. This course is of intermediate difficulty and will require Python and numpy knowledge.

At the end of this specialization you will have gained the prerequisite mathematical knowledge to continue your journey and take more advanced courses in machine learning.",Eigenvalues And Eigenvectors Principal Component Analysis (PCA) Multivariable Calculus Linear Algebra Basis (Linear Algebra) Transformation Matrix Linear Regression Vector Calculus Gradient Descent Dimensionality Reduction Python Programming
Hands-on Machine Learning with AWS and NVIDIA,AWS NVIDIA,Intermediate,Not available,https://in.coursera.org/learn/machine-learning-aws-nvidia,"Machine learning (ML) projects can be complex, tedious, and time consuming. AWS and NVIDIA solve this challenge with fast, effective, and easy-to-use capabilities for your ML project.

This course is designed for ML practitioners, including data scientists and developers, who have a working knowledge of machine learning workflows. In this course, you will gain hands-on experience on building, training, and deploying scalable machine learning models with Amazon SageMaker and Amazon EC2 instances powered by NVIDIA GPUs. Amazon SageMaker helps data scientists and developers prepare, build, train, and deploy high-quality ML models quickly by bringing together a broad set of capabilities purpose-built for ML. Amazon EC2 instances powered by NVIDIA GPUs along with NVIDIA software offer high performance GPU-optimized instances in the cloud for efficient model training and cost effective model inference hosting.

In this course, you will first get an overview of Amazon SageMaker and NVIDIA GPUs. Then, you will get hands-on, by running a GPU powered Amazon SageMaker notebook instance. You will then learn how to prepare a dataset for model training, build a model, execute model training, and deploy and optimize the ML model. You will also learn, hands-on, how to apply this workflow for computer vision (CV) and natural language processing (NLP) use cases. After completing this course, you will be able to build, train, deploy, and optimize ML workflows with GPU acceleration in Amazon SageMaker and understand the key Amazon SageMaker services applicable to computer vision and NLP ML tasks.",Natural Language Processing Machine Learning Operations (MLOps) NVIDIA GPU Acceleration Computer Vision Automated Machine Learning (AutoML)
Introduction to Machine Learning in Sports Analytics,Michigan University,Intermediate,4.5,https://in.coursera.org/learn/machine-learning-sports-analytics,"In this course students will explore supervised machine learning techniques using the python scikit learn (sklearn) toolkit and real-world athletic data to understand both machine learning algorithms and how to predict athletic outcomes. Building on the previous courses in the specialization, students will apply methods such as support vector machines (SVM), decision trees, random forest, linear and logistic regression, and ensembles of learners to examine data from professional sports leagues such as the NHL and MLB as well as wearable devices such as the Apple Watch and inertial measurement units (IMUs). By the end of the course students will have a broad understanding of how classification and regression techniques can be used to enable sports analytics across athletic activities and events.",Machine Learning Support Vector Machines Decision Trees 
Mathematics for Machine Learning: Multivariate Calculus,Imperial College London,Beginner,4.7,https://in.coursera.org/learn/multivariate-calculus-machine-learning,"This course offers a brief introduction to the multivariate calculus required to build many common machine learning techniques. We start at the very beginning with a refresher on the “rise over run” formulation of a slope, before converting this to the formal definition of the gradient of a function. We then start to build up a set of tools for making calculus easier and faster. Next, we learn how to calculate vectors that point up hill on multidimensional surfaces and even put this into action using an interactive game. We take a look at how we can use calculus to build approximations to functions, as well as helping us to quantify how accurate we should expect those approximations to be. We also spend some time talking about where calculus comes up in the training of neural networks, before finally showing you how it is applied in linear regression models. This course is intended to offer an intuitive understanding of calculus, as well as the language necessary to look concepts up yourselves when you get stuck. Hopefully, without going into too much detail, you’ll still come away with the confidence to dive into some more focused machine learning courses in future.",Linear Regression Vector Calculus Multivariable Calculus Gradient Descent
"Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning",DeepLearning.AI,Intermediate,4.7,https://in.coursera.org/learn/introduction-tensorflow,"If you are a software developer who wants to build scalable AI-powered algorithms, you need to understand how to use the tools to build them. This course is part of the upcoming Machine Learning in Tensorflow Specialization and will teach you best practices for using TensorFlow, a popular open-source framework for machine learning. 

The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization.",Computer Vision Tensorflow Machine Learning
Mathematics for Machine Learning: Linear Algebra,Imperial College London,Beginner,4.7,https://in.coursera.org/learn/linear-algebra-machine-learning,"In this course on Linear Algebra we look at what linear algebra is and how it relates to vectors and matrices. Then we look through what vectors and matrices are and how to work with them, including the knotty problem of eigenvalues and eigenvectors, and how to use these to solve problems. Finally  we look at how to use these to do fun things with datasets - like how to rotate images of faces and how to extract eigenvectors to look at how the Pagerank algorithm works.

Since we're aiming at data-driven applications, we'll be implementing some of these ideas in code, not just on pencil and paper. Towards the end of the course, you'll write code blocks and encounter Jupyter notebooks in Python, but don't worry, these will be quite short, focussed on the concepts, and will guide you through if you’ve not coded before.

At the end of this course you will have an intuitive understanding of vectors and matrices that will help you bridge the gap into linear algebra problems, and how to apply these concepts to machine learning.",Eigenvalues And Eigenvectors Basis (Linear Algebra) Transformation Matrix Linear Algebra
Practical Data Science on the AWS Cloud Specialization,DeepLearning.AI AWS,Advanced,4.6,https://in.coursera.org/specializations/practical-data-science,"Development environments might not have the exact requirements as production environments. Moving data science and machine learning projects from idea to production requires state-of-the-art skills. You need to architect and implement your projects for scale and operational efficiency. Data science is an interdisciplinary field that combines domain knowledge with mathematics, statistics, data visualization, and programming skills. 

The Practical Data Science Specialization brings together these disciplines using purpose-built ML tools in the AWS cloud. It helps you develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ML workflow using Amazon SageMaker. 

This Specialization is designed for data-focused developers, scientists, and analysts familiar with the Python and SQL programming languages who want to learn how to build, train, and deploy scalable, end-to-end ML pipelines - both automated and human-in-the-loop - in the AWS cloud.

Each of the 10 weeks features a comprehensive lab developed specifically for this Specialization that provides hands-on experience with state-of-the-art algorithms for natural language processing (NLP) and natural language understanding (NLU), including BERT and FastText using Amazon SageMaker.",Natural Language Processing with BERT ML Pipelines and ML Operations (MLOps) A/B Testing and Model Deployment Data Labeling at Scale Automated Machine Learning (AutoML) Statistical Data Bias Detection Multi-class Classification with FastText and BlazingText Data ingestion Exploratory Data Analysis ML Pipelines and MLOps Model Training and Deployment with BERT Model Debugging and Evaluation
IBM AI Enterprise Workflow Specialization,IBM,Advanced,4.4,https://in.coursera.org/specializations/ibm-ai-workflow,"This six course specialization is designed to prepare you to take the certification examination for IBM AI Enterprise Workflow V1 Data Science Specialist.  IBM AI Enterprise Workflow is a comprehensive, end-to-end process that enables data scientists to build AI solutions, starting with business priorities and working through to taking AI into production.  The learning aims to elevate the skills of practicing data scientists by explicitly connecting business priorities to technical implementations, connecting machine learning to specialized AI use cases such as visual recognition and NLP, and connecting Python to IBM Cloud technologies. The videos, readings, and case studies in these courses are designed to guide you through your work as a data scientist at a hypothetical streaming media company.

Throughout this specialization, the focus will be on the practice of data science in large, modern enterprises.  You will be guided through the use of enterprise-class tools on the IBM Cloud, tools that you will use to create, deploy and test machine learning models.  Your favorite open source tools, such a Jupyter notebooks and Python libraries will be used extensively for data preparation and building models.  Models will be deployed on the IBM Cloud using IBM Watson tooling that works seamlessly with open source tools.  After successfully completing this specialization, you will be ready to take the official IBM certification examination for the IBM AI Enterprise Workflow.",Data Science Information Engineering Artificial Intelligence (AI) Machine Learning Python Programming
Analyze Datasets and Train ML Models using AutoML,DeepLearning.AI AWS,Advanced,4.6,https://in.coursera.org/learn/automl-datasets-ml-models,"In the first course of the Practical Data Science Specialization, you will learn foundational concepts for exploratory data analysis (EDA), automated machine learning (AutoML), and text classification algorithms. With Amazon SageMaker Clarify and Amazon SageMaker Data Wrangler, you will analyze a dataset for statistical bias, transform the dataset into machine-readable features, and select the most important features to train a multi-class text classifier. You will then perform automated machine learning (AutoML) to automatically train, tune, and deploy the best text-classification algorithm for the given dataset using Amazon SageMaker Autopilot. Next, you will work with Amazon SageMaker BlazingText, a highly optimized and scalable implementation of the popular FastText algorithm, to train a text classifier with very little code.

Practical data science is geared towards handling massive datasets that do not fit in your local hardware and could originate from multiple sources. One of the biggest benefits of developing and running data science projects in the cloud is the agility and elasticity that the cloud offers to scale up and out at a minimum cost.

The Practical Data Science Specialization helps you develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ML workflow using Amazon SageMaker. This Specialization is designed for data-focused developers, scientists, and analysts familiar with the Python and SQL programming languages and want to learn how to build, train, and deploy scalable, end-to-end ML pipelines - both automated and human-in-the-loop - in the AWS cloud.",Statistical Data Bias Detection Multi-class Classification with FastText and BlazingText Data ingestion Exploratory Data Analysis Automated Machine Learning (AutoML)
Deep Learning Specialization,DeepLearning.AI,Intermediate,4.9,https://in.coursera.org/specializations/deep-learning,"The Deep Learning Specialization is a foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. 

In this Specialization, you will build and train neural network architectures such as Convolutional Neural Networks, Recurrent Neural Networks, LSTMs, Transformers, and learn how to make them better with strategies such as Dropout, BatchNorm, Xavier/He initialization, and more. Get ready to master theoretical concepts and their industry applications using Python and TensorFlow and tackle real-world cases such as speech recognition, music synthesis, chatbots, machine translation, natural language processing, and more.

AI is transforming many industries. The Deep Learning Specialization provides a pathway for you to take the definitive step in the world of AI by helping you gain the knowledge and skills to level up your career. Along the way, you will also get career advice from deep learning experts from industry and academia.",Artificial Neural Network Convolutional Neural Network Tensorflow Recurrent Neural Network Transformers Deep Learning Backpropagation Python Programming Neural Network Architecture Mathematical Optimization Hyperparameter tuning Inductive Transfer
"AI Workflow: Machine Learning, Visual Recognition and NLP",IBM,Advanced,4.4,https://in.coursera.org/learn/ibm-ai-workflow-machine-learning-vr-nlp,"This is the fourth course in the IBM AI Enterprise Workflow Certification specialization.    You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones. 

Course 4 covers the next stage of the workflow, setting up models and their associated data pipelines for a hypothetical streaming media company.  The first topic covers the complex topic of evaluation metrics, where you will learn best practices for a number of different metrics including regression metrics, classification metrics, and multi-class metrics, which you will use to select the best model for your business challenge.  The next topics cover best practices for different types of models including linear models, tree-based models, and neural networks.  Out-of-the-box Watson models for natural language understanding and visual recognition will be used.  There will be case studies focusing on natural language processing and on image analysis to provide realistic context for the model pipelines.
 
By the end of this course you will be able to:
Discuss common regression, classification, and multilabel classification metrics
Explain the use of linear and logistic regression in supervised learning applications
Describe common strategies for grid searching and cross-validation
Employ evaluation metrics to select models for production use
Explain the use of tree-based algorithms in supervised learning applications
Explain the use of Neural Networks in supervised learning applications
Discuss the major variants of neural networks and recent advances
Create a neural net model in Tensorflow
Create and test an instance of Watson Visual Recognition
Create and test an instance of Watson NLU

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 through 3 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",Data Science Information Engineering Artificial Intelligence (AI) Machine Learning Python Programming
Machine Learning Rapid Prototyping with IBM Watson Studio,IBM,Intermediate,Not available,https://in.coursera.org/learn/ibm-rapid-prototyping-watson-studio-autoai,"An emerging trend in AI is the availability of technologies in which automation is used to select a best-fit model, perform feature engineering and improve model performance via hyperparameter optimization. This automation will provide rapid-prototyping of models and allow the Data Scientist to focus their efforts on applying domain knowledge to fine-tune models. This course will take the learner through the creation of an end-to-end automated pipeline built by Watson Studio’s AutoAI experiment tool, explaining the underlying technology at work as developed by IBM Research. The focus will be on working with an auto-generated Python notebook. Learners will be provided with test data sets for two use cases.

This course is intended for practicing Data Scientists. While it showcases the automated AI capabilies of IBM Watson Studio with AutoAI, the course does not explain Machine Learning or Data Science concepts. 

In order to be successful, you should have knowledge of:

Data Science workflow
Data Preprocessing 
Feature Engineering 
Machine Learning Algorithms 
Hyperparameter Optimization
Evaluation measures for models 
Python and scikit-learn library (including Pipeline class)",Data Science Information Engineering Artificial Intelligence (AI) Machine Learning Python Programming
Generative Adversarial Networks (GANs) Specialization,DeepLearning.AI,Intermediate,4.7,https://in.coursera.org/specializations/generative-adversarial-networks-gans,"About GANs
Generative Adversarial Networks (GANs) are powerful machine learning models capable of generating realistic image, video, and voice outputs. 

Rooted in game theory, GANs have wide-spread application: from improving cybersecurity by fighting against adversarial attacks and anonymizing data to preserve privacy to generating state-of-the-art images, colorizing black and white images, increasing image resolution, creating avatars, turning 2D images to 3D, and more. 

About this Specialization
The DeepLearning.AI Generative Adversarial Networks (GANs) Specialization provides an exciting introduction to image generation with GANs, charting a path from foundational concepts to advanced techniques through an easy-to-understand approach. It also covers social implications, including bias in ML and the ways to detect it, privacy preservation, and more.

Build a comprehensive knowledge base and gain hands-on experience in GANs. Train your own model using PyTorch, use it to create images, and evaluate a variety of advanced GANs. 

About you
This Specialization is for software engineers, students, and researchers from any field, who are interested in machine learning and want to understand how GANs work.

This Specialization provides an accessible pathway for all levels of learners looking to break into the GANs space or apply GANs to their own projects, even without prior familiarity with advanced math and machine learning research.",Generator Image-to-Image Translation Glossary of computer graphics Discriminator Generative Adversarial Networks Controllable Generation WGANs Conditional Generation Components of GANs DCGANs Bias in GANs StyleGANs
AI Workflow: AI in Production,IBM,Advanced,4.5,https://in.coursera.org/learn/ibm-ai-workflow-ai-production,"This is the sixth course in the IBM AI Enterprise Workflow Certification specialization.   You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.    

This course focuses on models in production at a hypothetical streaming media company.  There is an introduction to IBM Watson Machine Learning.  You will build your own API in a Docker container and learn how to manage containers with Kubernetes.  The course also introduces  several other tools in the IBM ecosystem designed to help deploy or maintain models in production.  The AI workflow is not a linear process so there is some time dedicated to the most important feedback loops in order to promote efficient iteration on the overall workflow.
 
By the end of this course you will be able to:
1.  Use Docker to deploy a flask application
2.  Deploy a simple UI to integrate the ML model, Watson NLU, and Watson Visual Recognition
3.  Discuss basic Kubernetes terminology
4.  Deploy a scalable web application on Kubernetes 
5.  Discuss the different feedback loops in AI workflow
6.  Discuss the use of unit testing in the context of model production
7.  Use IBM Watson OpenScale to assess bias and performance of production machine learning models.

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 through 5 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",Data Science Information Engineering Artificial Intelligence (AI) Machine Learning Python Programming
Probabilistic Graphical Models 3: Learning,Stanford University,Advanced,4.6,https://in.coursera.org/learn/probabilistic-graphical-models-3-learning,"Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the third in a sequence of three. Following the first course, which focused on representation, and the second, which focused on inference, this course addresses the question of learning: how a PGM can be learned from a data set of examples. The course discusses the key problems of parameter estimation in both directed and undirected models, as well as the structure learning task for directed models. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of two commonly used learning algorithms are implemented and applied to a real-world problem.",Algorithms Expectation–Maximization (EM) Algorithm Graphical Model Markov Random Field
AI For Everyone,DeepLearning.AI,Beginner,4.8,https://in.coursera.org/learn/ai-for-everyone,"AI is not only for engineers. If you want your organization to become better at using AI, this is the course to tell everyone--especially your non-technical colleagues--to take. 

In this course, you will learn:

- The meaning behind common AI terminology, including neural networks, machine learning, deep learning, and data science
- What AI realistically can--and cannot--do
- How to spot opportunities to apply AI to problems in your own organization
- What it feels like to build machine learning and data science projects
- How to work with an AI team and build an AI strategy in your company
- How to navigate ethical and societal discussions surrounding AI

Though this course is largely non-technical, engineers can also take this course to learn the business aspects of AI.",Workflow of Machine Learning projects AI terminology AI strategy Workflow of Data Science projects
"ML Parameters Optimization: GridSearch, Bayesian, Random",Coursera,Beginner,Not available,https://in.coursera.org/projects/ml-parameters-optimization-gridsearch-bayesian-random,"Hello everyone and welcome to this new hands-on project on Machine Learning hyperparameters optimization. In this project, we will optimize machine learning regression models parameters using several techniques such as grid search, random search and Bayesian optimization. Hyperparameter optimization is a key step in developing machine learning models and it works by fine tuning ML models so they can optimally perform on a given dataset",Data Analysis Machine Learning Mathematical Optimization
AI in Healthcare Specialization,Stanford University,Beginner,4.7,https://in.coursera.org/specializations/ai-healthcare,"Artificial intelligence (AI) has transformed industries around the world, and has the potential to radically alter the field of healthcare. Imagine being able to analyze data on patient visits to the clinic, medications prescribed, lab tests, and procedures performed, as well as data outside the health system -- such as social media, purchases made using credit cards, census records, Internet search activity logs that contain valuable health information, and you’ll get a sense of how AI could transform patient care and diagnoses.

In this specialization, we'll discuss the current and future applications of AI in healthcare with the goal of learning to bring AI technologies into the clinic safely and ethically.  

This specialization is designed for both healthcare providers and computer science professionals, offering insights to facilitate collaboration between the disciplines.",Machine Learning in healthcare
Preparing for Google Cloud Certification: Cloud Data Engineer Professional Certificate,Google Cloud,Intermediate,4.6,https://in.coursera.org/professional-certificates/gcp-data-engineering,"Google Cloud Professional Data Engineer certification was ranked #1 on Global Knowledge's list of 15 top-paying certifications in 2021! Enroll now to prepare!

87% of Google Cloud certified users feel more confident in their cloud skills. This program provides the skills you need to advance your career and provides training to support your preparation for the industry-recognized Google Cloud Professional Data Engineer certification.

Here's what you have to do

1) Complete the Coursera Data Engineering Professional Certificate

2) Review other recommended resources for the Google Cloud Professional Data Engineer certification exam

3) Review the Professional Data Engineer exam guide

4) Complete Professional Data Engineer sample questions

5) Register for the Google Cloud certification exam (remotely or at a test center)

Applied Learning Project

This professional certificate incorporates hands-on labs using Qwiklabs platform.These hands on components will let you apply the skills you learn. Projects incorporate Google Cloud Platform products used within Qwiklabs. You will gain practical hands-on experience with the concepts explained throughout the modules.",Information Engineering Google Cloud Bigquery Tensorflow Cloud Computing Google Cloud Platform
A Crash Course in Data Science,Johns Hopkins University,Beginner,4.5,https://in.coursera.org/learn/data-science-course,"By now you have definitely heard about data science and big data. In this one-week class, we will provide a crash course in what these terms mean and how they play a role in successful organizations. This class is for anyone who wants to learn what all the data science action is about, including those who will eventually need to manage data scientists. The goal is to get you up to speed as quickly as possible on data science without all the fluff. We've designed this course to be as convenient as possible without sacrificing any of the essentials.

This is a focused course designed to rapidly get you up to speed on the field of data science. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward.

After completing this course you will know. 

1. How to describe the role data science plays in various contexts
2. How statistics, machine learning, and software engineering play a role in data science
3. How to describe the structure of a data science project
4. Know the key terms and tools used by data scientists
5. How to identify a successful and an unsuccessful data science project
3. The role of a data science manager",Data Science Data Analysis Machine Learning Project
AI Workflow: Data Analysis and Hypothesis Testing,IBM,Advanced,4.2,https://in.coursera.org/learn/ibm-ai-workflow-data-analysis-hypothesis-testing,"This is the second course in the IBM AI Enterprise Workflow Certification specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.  

In this course you will begin your work for a hypothetical streaming media company by doing exploratory data analysis (EDA).  Best practices for data visualization, handling missing data, and hypothesis testing will be introduced to you as part of your work.  You will learn techniques of estimation with probability distributions and extending these estimates to apply null hypothesis significance tests. You will apply what you learn through two hands on case studies: data visualization and multiple testing using a simple pipeline.
 
By the end of this course you should be able to:
1.  List several best practices concerning EDA and data visualization
2.  Create a simple dashboard in Watson Studio
3.  Describe strategies for dealing with missing data
4.  Explain the difference between imputation and multiple imputation
5.  Employ common distributions to answer questions about event probabilities
6.  Explain the investigative role of hypothesis testing in EDA
7.  Apply several methods for dealing with multiple testing",Data Science Information Engineering Artificial Intelligence (AI) Machine Learning Python Programming
AI Workflow: Business Priorities and Data Ingestion,IBM,Intermediate,4.3,https://in.coursera.org/learn/ibm-ai-workflow-business-priorities-data-ingestion,"This is the first course of a six part specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.

This first course in the IBM AI Enterprise Workflow Certification specialization introduces you to the scope of the specialization and prerequisites.  Specifically, the courses in this specialization are meant for practicing data scientists who are knowledgeable about probability, statistics, linear algebra, and Python tooling for data science and machine learning.  A hypothetical streaming media company will be introduced as your new client.  You will be introduced to the concept of design thinking, IBMs framework for organizing large enterprise AI projects.  You will also be introduced to the basics of scientific thinking, because the quality that distinguishes a seasoned data scientist from a beginner is creative, scientific thinking.  Finally you will start your work for the hypothetical media company by understanding the data they have, and by building a data ingestion pipeline using Python and Jupyter notebooks.
 
By the end of this course you should be able to:
1.  Know the advantages of carrying out data science using a structured process
2.  Describe how the stages of design thinking correspond to the AI enterprise workflow
3.  Discuss several strategies used to prioritize business opportunities
4.  Explain where data science and data engineering have the most overlap in the AI workflow
5.  Explain the purpose of testing in data ingestion 
6.  Describe the use case for sparse matrices as a target destination for data ingestion 
7.  Know the initial steps that can be taken towards automation of data ingestion pipelines","Data Science 
Information Engineering 
Artificial Intelligence (AI) 
Machine Learning 
Python Programming"
IBM Applied AI Professional Certificate,IBM,Beginner,4.6,https://in.coursera.org/professional-certificates/applied-artifical-intelligence-ibm-watson-ai,"Artificial intelligence (AI) is transforming our world. Whether you’re a student, a developer, or a technology consultant - understanding AI and knowing how to create AI-powered applications can give you an edge in your career. This Professional Certificate is designed to arm you with the skills to work as an AI developer. 

This program will give you a firm understanding of AI technology, its applications, and its use cases. You will become familiar with concepts and tools like machine learning, data science, natural language processing, image classification, image processing, IBM Watson AI services, OpenCV, and APIs. Even if you have no programming background, through this Professional Certificate, you will learn practical Python skills to design, build, and deploy AI applications on the web. The courses will also enable you to apply pre-built AI smarts to your products and solutions.

Rather than create complex AI algorithms and interfaces from scratch, you’ll use IBM Watson AI services and APIs to create smart applications with minimal coding. By the end of this Professional Certificate, you will have completed several projects that showcase proficiency in applying AI and building AI-powered solutions.

In addition to earning a Professional Certificate from Coursera, you'll also receive a digital badge from IBM recognizing your proficiency in applied AI. ","Data Science 
Deep Learning 
Artificial Intelligence (AI) 
Jobs 
Machine Learning 
Application Programming Interfaces (API) 
watson 
Python Programming 
Data Analysis 
Pandas 
Numpy 
Application development"
Big Data Specialization,UC San Diego,Beginner,4.5,https://in.coursera.org/specializations/big-data,"Do you need to understand big data and how it will impact your business? This Specialization is for you. You will gain an understanding of what insights big data can provide through hands-on experience with the tools and systems used by big data scientists and engineers. Previous programming experience is not required! You will be guided through the basics of using Hadoop with MapReduce, Spark, Pig and Hive. By following along with provided code, you will experience how one can perform predictive modeling and leverage graph analytics to model problems. This specialization will prepare you to ask the right questions about data, communicate effectively with data scientists, and do basic exploration of large, complex datasets. In the final Capstone Project, developed in partnership with data software company Splunk, you’ll apply the skills you learned to do basic analyses of big data",Big Data Neo4j Mongodb Apache Spark Apache Hadoop Mapreduce Cloudera Data Model Data Modeling Data Management Splunk Machine Learning Concepts
IBM Data Science Professional Certificate,IBM,Beginner,4.6,https://in.coursera.org/professional-certificates/ibm-data-science,"Data science is one of the hottest professions of the decade, and the demand for data scientists who can analyze data and communicate results to inform data driven decisions has never been greater. This Professional Certificate will help anyone interested in pursuing a career in data science or machine learning develop career-relevant skills.

It’s a myth that to become a data scientist you need a Ph.D. Anyone with a passion for learning can take this Professional Certificate – no prior knowledge of computer science or programming languages required – and develop the skills, tools, and portfolio to have a competitive edge in the job market as an entry level data scientist.

The program consists of 9 online courses that will provide you with the latest job-ready tools and skills, including open source tools and libraries, Python, databases, SQL, data visualization, data analysis, statistical analysis, predictive modeling, and machine learning algorithms. You’ll learn data science through hands-on practice in the IBM Cloud using real data science tools and real-world data sets.

Upon completing these courses, you will have built a portfolio of data science projects to provide you with the confidence to plunge into an exciting profession in data science.

In addition to earning a Professional Certificate from Coursera, you'll also receive a digital badge from IBM.

This program is ACE® recommended—when you complete, you can earn up to 12 college credits.",Data Science Deep Learning Machine Learning Big Data Data Mining Github Python Programming Jupyter notebooks Rstudio Methodology CRISP-DM Data Analysis
Optimize ML Models and Deploy Human-in-the-Loop Pipelines,DeepLearning.AI AWS,Advanced,4.7,https://in.coursera.org/learn/ml-models-human-in-the-loop-pipelines,"In the third course of the Practical Data Science Specialization, you will learn a series of performance-improvement and cost-reduction techniques to automatically tune model accuracy, compare prediction performance, and generate new training data with human intelligence.  After tuning your text classifier using Amazon SageMaker Hyper-parameter Tuning (HPT), you will deploy two model candidates into an A/B test to compare their real-time prediction performance and automatically scale the winning model using Amazon SageMaker Hosting. Lastly, you will set up a human-in-the-loop pipeline to fix misclassified predictions and generate new training data using Amazon Augmented AI and Amazon SageMaker Ground Truth.
Practical data science is geared towards handling massive datasets that do not fit in your local hardware and could originate from multiple sources. One of the biggest benefits of developing and running data science projects in the cloud is the agility and elasticity that the cloud offers to scale up and out at a minimum cost.

The Practical Data Science Specialization helps you develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ML workflow using Amazon SageMaker. This Specialization is designed for data-focused developers, scientists, and analysts familiar with the Python and SQL programming languages and want to learn how to build, train, and deploy scalable, end-to-end ML pipelines - both automated and human-in-the-loop - in the AWS cloud",Human-in-the-Loop Pipelines Distributed Model Training and Hyperparameter Tuning Cost Savings and Performance Improvements A/B Testing and Model Deployment Data Labeling at Scale
IBM AI Foundations for Business Specialization,IBM,Beginner,4.7,https://in.coursera.org/specializations/ibm-ai-foundations-for-business,"This specialization will explain and describe the overall focus areas for business leaders considering AI-based solutions for business challenges. The first course provides a business-oriented summary of technologies and basic concepts in AI. The second will introduce the technologies and concepts in data science. The third introduces the AI Ladder, which is a framework for understanding the work and processes that are necessary for the successful deployment of AI-based solutions. ","Data Science Artificial Intelligence (AI) Information Technology (IT) Architecture Data Architecture Leadership Deep Learning Jobs Machine Learning Big Data 
Data Mining Management Analytics"
Probabilistic Graphical Models 1: Representation,Stanford University,Advanced,4.6,https://in.coursera.org/learn/probabilistic-graphical-models,"Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the first in a sequence of three. It describes the two basic PGM representations: Bayesian Networks, which rely on a directed graph; and Markov networks, which use an undirected graph. The course discusses both the theoretical properties of these representations as well as their use in practice. The (highly recommended) honors track contains several hands-on assignments on how to represent some real-world problems. The course also presents some important extensions beyond the basic PGM representation, which allow more complex models to be encoded compactly.",Bayesian Network Graphical Model Markov Random Field
Information Extraction from Free Text Data in Health,Michigan University,Intermediate,Not available,https://in.coursera.org/learn/information-extraction-from-free-text-data-in-health-2,"In this MOOC, you will be introduced to advanced machine learning and natural language

processing techniques to parse and extract information from unstructured text documents in
healthcare, such as clinical notes, radiology reports, and discharge summaries. Whether you are an aspiring data scientist or an early or mid-career professional in data science or information technology in healthcare, it is critical that you keep up-to-date your skills in information extraction and analysis. 

To be successful in this course, you should build on the concepts learned through other intermediate-level MOOC courses and specializations in Data Science offered by the University of Michigan, so you  will be able to delve deeper into challenges in recognizing medical entities in health-related documents, extracting clinical information, addressing ambiguity and polysemy to tag them with correct concept types, and develop tools and techniques to analyze new genres of health information.

By the end of this course, you will be able to: 
Identify text mining approaches needed to identify and extract different kinds of information from health-related text data
Create an end-to-end NLP pipeline to extract medical concepts from clinical free text using one terminology resource
Differentiate how training deep learning models differ from training traditional machine learning models
Configure a deep neural network model to detect adverse events from drug reviews
List the pros and cons of Deep Learning approaches.""",Information Extraction Python Libraries Python Programming Computer Programming Tools Computer Programming
Key Technologies for Business Specialization,IBM,Beginner,4.7,https://in.coursera.org/specializations/key-technologies-for-business,"In this Specialization, we will cover 3 key technologies that are foundational and driving significant growth and innovation. These are Cloud Computing, Data Science, and Artificial Intelligence (AI).

Technology is essential for the future of business. Almost any organization that wants to modernize or get ahead, and anyone working there, needs to understand and leverage these essential technologies.

The courses in this Specialization provide foundational knowledge of Cloud, Data and AI, including business drivers behind their growth, the value they provide, their applications and use cases, and an understanding of how these technologies work. You will not only become familiar with the buzzwords associated with these technologies, but also experience them in action and develop hands-on skills to start working with them.

This Specialization is suitable for a variety of learners who are beginners with these technologies, including managers and executives, professionals who want to upskill, and students getting ready to start a career.

There is no special prior knowledge or hardware required. The only pre-requisites are basic computer literacy, device with a modern web browser with internet connectivity, and motivation to self-learn online.","Data Science Artificial Intelligence (AI) Business Cloud Computing 
technology Cloud Native Devops Iaas PaaS Saas Hybrid Multicloud Deep Learning 
Jobs Machine Learning"
CertNexus Certified Data Science Practitioner Professional Certificate,Certnexus,Intermediate,4.8,https://in.coursera.org/professional-certificates/certified-data-science-practitioner,"The field of Data Science has topped the Linked In Emerging Jobs list for the last 3 years with a projected growth of 28% annually and the World Economic Forum lists Data Analytics and Scientists as the top emerging job for 2022. 

Data can reveal insights and inform business—by guiding decisions and influencing day-to-day operations. This specialization will teach learners how to analyze, understand, manipulate, and present data within an effective and repeatable process framework and will enable you to bring value to the business by putting data science concepts into practice. 

This course is designed for business professionals that want to learn how to more effectively extract insights from their work and leverage that insight in addressing business issues, thereby bringing greater value to the business. The typical student in this course will have several years of experience with computing technology, including some aptitude in computer programming.

Certified Data Science Practitioner (CDSP)  will prepare learners for the CertNexus CDSP certification exam. 

To complete your journey to the CDSP Certification

Complete the Coursera Certified Data Science Practitioner Professional Certificate.

Review the CDSP Exam Blueprint.

Purchase your CDSP Exam Voucher.

 Register for your CDSP Exam.","Data Manipulation Machine Learning Data Analysis Extraction, Transformation And Loading (ETL) Data Model Data-Informed Decision-Making Scope (Project Management) Business Process Cleaning Data Mining Data Insight Dissemination"
Applied Social Network Analysis in Python,Michigan University,Intermediate,4.6,https://in.coursera.org/learn/python-social-network-analysis,"This course will introduce the learner to network analysis through tutorials using the NetworkX library. The course begins with an understanding of what network analysis is and motivations for why we might model phenomena as networks. The second week introduces the concept of connectivity and network robustness. The third week will explore ways of measuring the importance or centrality of a node in a network. The final week will explore the evolution of networks over time and cover models of network generation and the link prediction problem. 

This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.",Graph Theory Network Analysis Python Programming Social Network Analysis
Introduction to Data Science Specialization,IBM,Beginner,4.7,https://in.coursera.org/specializations/introduction-data-science,"Interested in learning more about data science, but don’t know where to start? This 4-course Specialization from IBM will provide you with the key foundational skills any data scientist needs to prepare you for a career in data science or further advanced learning in the field.  

This Specialization will introduce you to what data science is and what data scientists do. You’ll discover the applicability of data science across fields, and learn how data analysis can help you make data driven decisions. You’ll find that you can kickstart your career path in the field without prior knowledge of computer science or programming languages: this Specialization will give you the foundation you need for more advanced learning to support your career goals.

You’ll grasp concepts like big data, statistical analysis, and relational databases, and gain familiarity with various open source tools and data science programs used by data scientists, like Jupyter Notebooks, RStudio, GitHub, and SQL. You'll complete hands-on labs and projects to learn the methodology involved in tackling data science problems and apply your newly acquired skills and knowledge to real world data sets.

In addition to earning a Specialization completion certificate from Coursera, you’ll also receive a digital badge from IBM recognizing you as a specialist in data science foundations.

This Specialization can also be applied toward the IBM Data Science Professional Certificate. ","Data Science Relational Database Management System (RDBMS) Cloud Databases 
Python Programming SQL Deep Learning Machine Learning Big Data Data Mining Github Jupyter notebooks Rstudio"
"Introduction to Data, Signal, and Image Analysis with MATLAB",Vanderbilt University,Intermediate,4.7,https://in.coursera.org/learn/matlab-image-processing,"Welcome to Introduction to Data, Signal, and Image Analysis with MATLAB!     

MATLAB is an extremely versatile programming language for data, signal, and image analysis tasks. This course provides an introduction on how to use MATLAB for data, signal, and image analysis. After completing the course,  learners will understand how machine learning methods can be used in MATLAB for data classification and prediction; how to perform data visualization, including data visualization for high dimensional datasets; how to perform image processing and analysis methods, including image filtering and image segmentation; and how to perform common signal analysis tasks, including filter design and frequency analysis.",MATLAB Image Analysis Signal Data Image processing Data classification Data visualization
CertNexus Certified Ethical Emerging Technologist Professional Certificate,Certnexus,Beginner,4.6,https://in.coursera.org/professional-certificates/certified-ethical-emerging-technologist,"The Certified Ethical Emerging Technologist (CEET) industry validated certification helps professionals differentiate themselves from other job candidates by demonstrating their ability to ethically navigate data driven emerging technologies such as AI, Machine Learning and Data Science.

Organizations and governments are seeking out ethics professionals to minimize risk and guide their decision-making about the design of inclusive, responsible, and trusted technology. An algorithm not designed and assessed in alignment with ethical standards can create further inequity across race, gender and marginalized populations. The reputational and financial impact of an ethics violation can devastate a company. Knowledgeable ethics leaders are needed who can navigate through the more than 160 frameworks and guidelines to select and implement the best strategy to promote fairness and minimize risk for their organization. This specialization is designed for learners who want to create and lead initiatives that prioritize ethical integrity within emerging data-driven technology fields such as artificial intelligence and data science and will be prepared to bridge the gap between theory and practice.

Your journey to CEET Certification 

1) Complete the Coursera Certified Ethical Emerging Technologist Professional Certificate

2) Review the CEET CET-110 Exam Blueprint

3) Purchase your CEET Exam Voucher 

4) Register for your CEET Exam ",Business Analysis Information Privacy Business Strategy Compliance Ethics Of Artificial Intelligence Risk Management General Statistics Risk Assessment Privacy Marketing Leadership And Management Communication
Neural Networks and Deep Learning,DeepLearning.AI,Intermediate,4.9,https://in.coursera.org/learn/neural-networks-deep-learning,"In the first course of the Deep Learning Specialization, you will study the foundational concept of neural networks and deep learning. 

By the end, you will be familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",Deep Learning Artificial Neural Network Backpropagation Python Programming Neural Network Architecture
Data Science: Foundations using R Specialization,Johns Hopkins University,Beginner,4.6,https://in.coursera.org/specializations/data-science-foundations-r,"Ask the right questions, manipulate data sets, and create visualizations to communicate results.
This Specialization covers foundational data science tools and techniques, including getting, cleaning, and exploring data, programming in R, and conducting reproducible research. Learners who complete this specialization will be prepared to take the Data Science: Statistics and Machine Learning specialization, in which they build a data product using real-world data.

The five courses in this specialization are the very same courses that make up the first half of the Data Science Specialization. This specialization is presented for learners who want to start and complete the foundational part of the curriculum first, before moving onto the more advanced topics in Data Science: Statistics and Machine Learning.","Data Science Machine Learning Github R Programming Exploratory Data Analysis 
Rstudio Data Analysis Debugging Data Manipulation Regular Expression (REGEX) Data Cleansing Cluster Analysis"
Introduction to Data Science in Python,Michigan University,Intermediate,4.5,https://in.coursera.org/learn/python-data-analysis,"This course will introduce the learner to the basics of the python programming environment, including fundamental python programming techniques such as lambdas, reading and manipulating csv files, and the numpy library. The course will introduce data manipulation and cleaning techniques using the popular python pandas data science library and introduce the abstraction of the Series and DataFrame as the central data structures for data analysis, along with tutorials on how to use functions such as groupby, merge, and pivot tables effectively. By the end of this course, students will be able to take tabular data, clean it, manipulate it, and run basic inferential statistical analyses. 

This course should be taken before any of the other Applied Data Science with Python courses: Applied Plotting, Charting & Data Representation in Python, Applied Machine Learning in Python, Applied Text Mining in Python, Applied Social Network Analysis in Python.",Python Programming Numpy Pandas Data Cleansing
"Applied Plotting, Charting & Data Representation in Python",Michigan University,Intermediate,4.5,https://in.coursera.org/learn/python-plotting,"This course will introduce the learner to information visualization basics, with a focus on reporting and charting using the matplotlib library. The course will start with a design and information literacy perspective, touching on what makes a good and bad visualization, and what statistical measures translate into in terms of visualizations. The second week will focus on the technology used to make visualizations in python, matplotlib, and introduce users to best practices when creating basic charts and how to realize design decisions in the framework. The third week will be a tutorial of functionality available in matplotlib, and demonstrate a variety of basic statistical charts helping learners to identify when a particular method is good for a particular problem. The course will end with a discussion of other forms of structuring and visualizing data. 

This course should be taken after Introduction to Data Science in Python and before the remainder of the Applied Data Science with Python courses: Applied Machine Learning in Python, Applied Text Mining in Python, and Applied Social Network Analysis in Python.",Python Programming Data Virtualization Data Visualization (DataViz) Matplotlib
Wearable Technologies and Sports Analytics,Michigan University,Intermediate,4.8,https://in.coursera.org/learn/wearable-technologies,"Sports analytics now include massive datasets from athletes and teams that quantify both training and competition efforts.  Wearable technology devices are being worn by athletes everyday and provide considerable opportunities for an in-depth look at the stress and recovery of athletes across entire seasons.  The capturing of these large datasets has led to new hypotheses and strategies regarding injury prevention as well as detailed feedback for athletes to try and optimize training and recovery.

This course is an introduction to wearable technology devices and their use in training and competition as part of the larger field of sport sciences.  It includes an introduction to the physiological principles that are relevant to exercise training and sport performance and how wearable devices can be used to help characterize both training and performance.  It includes access to some large sport team datasets and uses programming in python to explore concepts related to training, recovery and performance.",Wearable Technology 
Innovations in Investment Technology: Artificial Intelligence,Michigan University,Beginner,4.7,https://in.coursera.org/learn/invest-tech,"Explore the evolution of AI investing and online wealth management.

Investing and managing your wealth online has never been easier, but how does AI investing work and what are the challenges?

On this course, you’ll explore how technology has changed the way we invest money. You’ll consider the evolution of AI-driven online wealth management platforms, robo-advisors, and learn how they work and why they’re successful.

Moving from human-based data-driven investing strategies to neural networks, you’ll assess the ability of artificial intelligence to make investment decisions and discover the role of AI and machine learning in making trading decisions.",Robo advising Investment technology Artificial Intelligence (AI) Investing technology Diversified portfolio
Neuronales Netz von Scratch,Coursera,Beginner,Not available,https://in.coursera.org/projects/neuronales-netz-von-scratch-tensorflow,Neuronales Netz von Scratch,Computer Programming Python Programming Machine Learning
Cloud Computing Basics (Cloud 101),"
LearnQuest",Beginner,4.5,https://in.coursera.org/learn/cloud-computing-basics,"Welcome to Cloud Computing Basics (Cloud 101). 

Over the next few weeks, we will discuss the basics of Cloud computing: what it is, what it supports, and how it is delivered. We will delve into storage services, Cloud economics, levels of managed infrastructure, and Azure services. We will also explore different deployment models of Cloud computing, as well as several hosting scenarios. Last but not least, we will compare some of the cloud platforms and discuss the future of cloud computing.", Azure Services and APIs Cloud computing Cloud Service Platforms
DevOps on AWS: Operate and Monitor,AWS,Intermediate,4.6,https://in.coursera.org/learn/devops-aws-operate-monitor,"The third and the final course in the DevOps series will teach how to use AWS Services to control the architecture in order to reach a better operational state. Monitoring and Operation are key aspects for both the release pipeline and production environments, because they provide instruments that help discover what's happening, as well as do modifications and enhancements on infrastructure that is currently running. 

This course teaches how to use Amazon CloudWatch for monitoring, as well as Amazon EventBridge and AWS Config for continuous compliance. It also covers Amazon CloudTrail and a little bit of Machine Learning for Monitoring operations!",CI/CD aws Devops
Politics and Ethics of Data Analytics in the Public Sector,Michigan University,Intermediate,Not available,https://in.coursera.org/learn/politics-and-ethics-of-data-analytics-in-the-public-sector,"Deepen your understanding of the power and politics of data in the public sector, including how values — in addition to data and evidence — are always part of public sector decision-making. In this course, you will explore common ethical challenges associated with data, data analytics, and randomized controlled trials in the public sector. You will also navigate and understand the ethical issues related to data systems and data analysis by understanding frameworks, codes of ethics, and professional guidelines. Using two technical case studies, you will understand common ethical issues, including participation bias in populations and how slicing analysis is used to identify bias in predictive machine learning models. This course also serves as a capstone experience for the Data Analytics in the Public Sector with R Specialization, where you will conduct an applied policy options analysis using authentic data from a real-world case study. In this capstone exercise, you will review data as part of policy options analysis, create a visualization of the results, and make a recommendation.

All coursework is completed in RStudio in Coursera without the need to install additional software.

This is the fourth and final course within the Data Analytics in the Public Sector with R Specialization. The series is ideal for current or early-career professionals working in the public sector looking to gain skills in analyzing public data effectively. It is also ideal for current data analytics professionals or students looking to enter the public sector.",Power and Politics of Data Data Analysts 
Simple Parallel Coordinates Plot using d3 js,Coursera,Intermediate,Not available,https://in.coursera.org/projects/simple-parallel-coordinates-plot-pcp-d3-js,Throughout this guided project we are going to create a simple Parallel Coordinates Plot (PCP) using d3 js. PCP is one of the most common data visualization techniques used to visualize high-dimensional datasets. In this guided project you will create a simple PCP step by step. We will also cover some important topics in data visualization such as Linear and Ordinal scaling to best visualize our data. Having the knowledge of javascript programming language and the basics of d3 js are the two most important prerequisites to get the most out of this guided project.,D3 js Data  Analysis MicrosoftVisual Studio Data Visualization (DataViz) JavaScript
Introduction to Statistics,Stanford University,Beginner,4.6,https://in.coursera.org/learn/stanford-statistics,"Stanford's ""Introduction to Statistics"" teaches you statistical thinking concepts that are essential for learning from data and communicating insights. By the end of the course, you will be able to perform exploratory data analysis, understand key principles of sampling, and select appropriate tests of significance for multiple contexts. You will gain the foundational skills that prepare you to pursue more advanced topics in statistical thinking and machine learning.

Topics include Descriptive Statistics, Sampling and Randomized Controlled Experiments, Probability, Sampling Distributions and the Central Limit Theorem, Regression, Common Tests of Significance, Resampling, Multiple Comparisons.",Descriptive Statistics Sampling and Randomized Controlled Experiments Probability Sampling Distributions and the Central Limit Theorem Regression Common Tests of Significance Resampling Multiple Comparisons
DevOps on AWS Specialization,AWS,Intermediate,4.7,https://in.coursera.org/specializations/aws-devops,"DevOps on AWS specialization teaches you how to use the combination of DevOps philosophies, practices and tools to develop, deploy, and maintain applications in the AWS Cloud. Benefits of adopting DevOps include: rapid delivery, reliability, scalability, security and improved collaboration.

The first course introduces you to essential AWS products, services, and common solutions. The course covers the fundamental concepts of compute, database, storage, networking, monitoring and security that learners and professionals will need to know when working with AWS.

The second course in the specialization discusses topics such as source control, best practices for Continuous Integration, and how to use the right tools to measure code quality, by identifying workflow steps that could be automated.

The third course explains how to improve the deployment process with DevOps methodology, and also some tools that might make deployments easier, such as Infrastructure as Code, or IaC, and AWS CodeDeploy.

Finally, the last course teaches how to use Amazon CloudWatch for monitoring, as well as Amazon EventBridge and AWS Config for continuous compliance. It also covers Amazon CloudTrail and a little bit of Machine Learning for Monitoring operations.",Continuous Integration Devops Monitoring and Logging Continuous Delivery Microservices AWS Identity and Access Management Networking on AWS AWS Management Console Cloud Computing Aws security Test Automation AWS cloud
Learn SQL Basics for Data Science Specialization,University of California,Beginner,4.5,https://in.coursera.org/specializations/learn-sql-basics-data-science,"This Specialization is intended for a learner with no previous coding experience seeking to develop SQL query fluency. Through four progressively more difficult SQL projects with data science applications, you will cover topics such as SQL basics, data wrangling, SQL analysis, AB testing, distributed computing using Apache Spark, Delta Lake and more. These topics will prepare you to apply SQL creatively to analyze and explore data; demonstrate efficiency in writing queries; create data analysis datasets; conduct feature engineering, use SQL with other data analysis and machine learning toolsets; and use SQL with unstructured data sets.",Data Analysis Apache Spark Delta Lake SQL Data Science Sqlite A/B Testing Query String Predictive Analytics Presentation Skills Creating metrics Exploratory Data Analysis
Meta Database Engineer Professional Certificate,Meta,Beginner,4.6,https://in.coursera.org/professional-certificates/meta-database-engineer,"Want to get started in the world of database engineering? This program is taught by industry-recognized experts at Meta. You’ll learn the key skills required to create, manage and manipulate databases, as well as industry-standard programming languages and software such as SQL, Python, and Django. 

Upon completion, you’ll get access to the Meta Career Programs Job Board—a job search platform that connects you with 200+ employers who have committed to sourcing talent through Meta’s certificate programs, as well as career support resources to help you with your job search.

In this program, you’ll learn:

Core techniques and methods to structure and manage databases. 

Advanced techniques to write database driven applications and advanced data modeling concepts. 

MySQL database management system (DBMS) and data creation, querying and manipulation.

How to code and use Python Syntax

How to prepare for technical interviews for database engineer roles.

Any third-party trademarks and other intellectual property (including logos and icons) referenced in the learning experience remain the property of their respective owners. Unless specifically identified as such, Coursera’s use of third-party intellectual property does not indicate any relationship, sponsorship, or endorsement between Coursera and the owners of these trademarks or other intellectual property.","SQL and Python syntax Database management Database administration MySQL 
Tabular records Database (DBMS) Linux Web Development Bash (Unix Shell) Github 
Version Control Data Management"
CAD and Digital Manufacturing Specialization,Autodesk,Intermediate,4.7,https://in.coursera.org/specializations/cad-design-digital-manufacturing,"The future of making is here, bringing with it radical changes in the way things are designed, made, and used. And it’s disrupting every industry. With the right knowledge and tools, this disruption is your opportunity—whether you're an entrepreneur, designer, or engineer. 

Today’s dominant technology trends—cloud computing, mobile technology, social connection, and collaboration—are driving businesses and consumers alike to explore profoundly different ways to design, make, and use things. This kind of industry transformation has happened before, but the pace of change is now much faster. In today’s competitive landscape, anyone can be an innovator—and it’s all about who innovates first. 

Through this specialization, you will learn the foundations of product innovation and digital manufacturing while developing your technical skills within Autodesk® Fusion 360™.

Plus, by completing this Specialization, you’ll unlock an Autodesk Credential as further recognition of your success! The Autodesk Credential comes with a digital badge and certificate, which you can add to your resume and share on social media platforms like LinkedIn, Facebook, and Twitter. Sharing your Autodesk Credential can signal to hiring managers that you’ve got the right skills for the job and you’re up on the latest industry trends like digital manufacturing.

Looking for Autodesk Fusion 360 certification prep courses? Check out additional learning resources to help you uplevel your skills.",Computer-Aided Design (CAD) Autodesk Manufacturing Processes Sustainable Design Mechanical Design 3d modeling Autocad
Improve Your Java Code Using Amazon CodeGuru,AWS,Intermediate,4.9,https://in.coursera.org/learn/aws-improve-java-code-amazon-codeguru,"Learn how to use Amazon CodeGuru Reviewer to automatically identify issues and vulnerabilities to improve your code quality with Improve your Python Code using Amazon CodeGuru. This course is designed for Python developers who are interested in learning how to use CodeGuru Reviewer to save time and improve their code review process.

In this course, you’ll learn how to use CodeGuru Reviewer to detect issues and identify recommendations to improve the quality and security of your code. The course demonstrates how CodeGuru Reviewer finds code anomalies and explains how to understand and apply its automated suggestions.

Developed at the source, this new digital course empowers you to learn about Amazon CodeGuru from the experts at AWS whenever, wherever you want. Advance your skills and knowledge to build your future in the AWS Cloud. Enroll today!

Note: There are two versions of this course: ""Improve Your Java Code Using Amazon CodeGuru"" for Java developers and ""Improve Your Python Code Using Amazon CodeGuru"" for Python developers. The courses do for a large part, overlap and in general, we recommend that you take the course that focuses on the SDK you plan to use to develop your AWS Cloud based applications.",Amazon CodeGuru Reviewer
Improve Your Python Code Using Amazon CodeGuru,AWS,Intermediate,4.8,https://in.coursera.org/learn/aws-improve-python-code-amazon-codeguru,"Learn how to use Amazon CodeGuru Reviewer to automatically identify issues and vulnerabilities to improve your code quality with our new digital course, Improve your Python Code using Amazon CodeGuru. This course is designed for Python developers who are interested in learning how to use CodeGuru Reviewer to save time and improve their code review process.

In this course, you’ll learn how to use CodeGuru Reviewer to detect issues and identify recommendations to improve the quality and security of your code. The course demonstrates how CodeGuru Reviewer finds code anomalies and explains how to understand and apply its automated suggestions.

Developed at the source, this new digital course empowers you to learn about Amazon CodeGuru from the experts at AWS whenever, wherever you want. Advance your skills and knowledge to build your future in the AWS Cloud. Enroll today!

Note: There are two versions of this course: ""Improve Your Java Code Using Amazon CodeGuru"" for Java developers and ""Improve Your Python Code Using Amazon CodeGuru"" for Python developers. The courses do for a large part, overlap and in general, we recommend that you take the course that focuses on the SDK you plan to use to develop your AWS Cloud based applications.",Amazon CodeGuru Reviewer
SAS Programmer Professional Certificate,SAS,Beginner,4.8,https://in.coursera.org/professional-certificates/sas-programming,"When you complete the SAS® Base Programming courses, you will have demonstrated skills in manipulating and transforming data, combining SAS data sets, creating basic detail and summary reports using SAS procedures and identifying and correcting data, syntax and programming logic errors.  These skills prepare you for the SAS® Base Programming Specialist certification exam. ",SAS Studio Import Data Reports Prepare Data SAS Programs
The AI Ladder: A Framework for Deploying AI in your Enterprise,IBM,Beginner,4.7,https://in.coursera.org/learn/ibm-ai-ladder-framework,"This course is intended for business and technical professionals involved in strategic decision-making focused on bringing AI into their enterprises. Through the use of a conceptual model called “The AI Ladder”, participants in this course will learn the requirements, terms and concepts associated with successfully developing and deploying AI solutions in their enterprises.  After completing this course you will be able to explain and describe each of the steps required to ensure success when you build and deploy AI solutions in your business enterprise.",Artificial Intelligence (AI) Management Analytics Innovation Leadership
DevOps on AWS: Release and Deploy,AWS,Intermediate,4.7,https://in.coursera.org/learn/devops-aws-release-deploy,"AWS provides a set of flexible services designed to enable companies to more rapidly and reliably build and deliver products using AWS and DevOps practices. These services simplify provisioning and managing infrastructure, deploying application code, automating software release processes, and monitoring your application and infrastructure performance. 

The third course in the series explains how to improve the deployment process with DevOps methodology, and also some tools that might make deployments easier, such as Infrastructure as Code, or IaC, and AWS CodeDeploy.

The course begins with reviewing topics covered in the first course of the DevOps on AWS series. You will learn about the differences between continuous integration, continuous delivery, and continuous deployment. In Exercises 1 and 2, you will set up AWS CodeDeploy and make revisions that will then be deployed. If you use AWS Lambda, you will explore ways to address additional considerations when you deploy updates to your Lambda functions.

Next, you will explore how infrastructure as code (IaC) helps organizations achieve automation, and which AWS solutions provide a DevOps-focused way of creating and maintaining infrastructure. In Exercise 3, you will be provided with an AWS CloudFormation template that will set up backend services, such as AWS CodePipeline, AWS CodeCommit, AWS CodeDeploy, and AWS CodeBuild. You will then upload new revisions to the pipeline.",Aws Continuous Integration Continuous Delivery Devops
Financial Technology (Fintech) Innovations Specialization,Michigan University,Beginner,4.7,https://in.coursera.org/specializations/financialtechnology,"This specialization is intended to familiarize learners with a broad range of financial technologies. While finance has always been at the forefront of technological innovation, the financial industry is changing rapidly in the face of new technology.  In the past, at the forefront of innovation in finance were central governments and financial institutions. Today, information technology firms and professionals are leading innovation in the financial industry.

Our goal is to show learners the genesis and use cases of the technology. We hope to familiarize professionals sufficiently with the technology that they can utilize and adapt the technologies in their careers.",Credit Technology Cryptocurrency Smart Investing Blockchain Payment Systems Processing payments Payment Processing Payment technology Value Propositions Decentralization algorithms Consensus algorithms Blockchain as a business solution
Data Science Specialization,Johns Hopkins University,Beginner,4.5,https://in.coursera.org/specializations/jhu-data-science,"Ask the right questions, manipulate data sets, and create visualizations to communicate results.
This Specialization covers the concepts and tools you'll need throughout the entire data science pipeline, from asking the right kinds of questions to making inferences and publishing results. In the final Capstone Project, you’ll apply the skills learned by building a data product using real-world data. At completion, students will have a portfolio demonstrating their mastery of the material. ",Github Machine Learning R Programming Regression Analysis Data Science Rstudio Data Analysis Debugging Data Manipulation Regular Expression (REGEX) Data Cleansing Cluster Analysis
Linux and Bash for Data Engineering,Duke University,Intermediate,4.5,https://in.coursera.org/learn/linux-and-bash-for-data-engineering-duke,"In this second course of the Python, Bash and SQL Essentials for Data Engineering Specialization, you will learn the fundamentals of Linux necessary to perform data engineering tasks. Additionally, you will explore how to use both Bash and zsh configurations, and develop the syntax needed to interact and control Linux. These skills will allow you to manage and manipulate databases in a Bash environment.",Bash (Unix Shell) Database (DBMS) Data Management Linux
Fitting Statistical Models to Data with Python,Michigan University,Intermediate,4.4,https://in.coursera.org/learn/fitting-statistical-models-data-python,"In this course, we will expand our exploration of statistical inference techniques by focusing on the science and art of fitting statistical models to data. We will build on the concepts presented in the Statistical Inference course (Course 2) to emphasize the importance of connecting research questions to our data analysis methods. We will also focus on various modeling objectives, including making inference about relationships between variables and generating predictions for future observations.

This course will introduce and explore various statistical modeling techniques, including linear regression, logistic regression, generalized linear models, hierarchical and mixed effects (or multilevel) models, and Bayesian inference techniques. All techniques will be illustrated using a variety of real data sets, and the course will emphasize different modeling approaches for different types of data sets, depending on the study design underlying the data (referring back to Course 1, Understanding and Visualizing Data with Python).

During these lab-based sessions, learners will work through tutorials focusing on specific case studies to help solidify the week’s statistical concepts, which will include further deep dives into Python libraries including Statsmodels, Pandas, and Seaborn. This course utilizes the Jupyter Notebook environment within Coursera.",Bayesian Statistics Python Programming Statistical Model Statistical regression
Data Analytics in the Public Sector with R Specialization,Michigan University,Intermediate,Not available,https://in.coursera.org/specializations/data-analytics-in-the-public-sector-with-r,"Every government entity collects and stores millions of data points to perform administrative and legislative duties, allocate resources, and make decisions. Professionals in the public sector need the necessary skills to accurately interpret and inform administrators and policymakers about the meaning behind these data.

This Specialization will equip you with fundamental technical skills using the R programming language to gather, manipulate, analyze, visualize, and interpret data to inform public policy and public administrative functions. Throughout four courses, you will gain new skills using the popular tidyverse packages, such as dplyr for data manipulation and ggplot for visualization. You will identify and address common political and ethical challenges in data analysis, and better understand public administration and public policy concepts using hands-on activities with real-world data sets.

This course series is ideal for current or early-career professionals in the public sector looking to gain skills in analyzing public data effectively.

There are no prerequisites, though programming experience, ideally with the R language, and basic applied statistics knowledge are recommended. The Google Data Analytics Professional Certificate offers such foundational skills. You will earn a dual badge when you complete the Google Career Certificate and this Specialization. All coursework is completed in RStudio in Coursera without the need to install additional software",Data Analysis Ggplot2 Data Visualization (DataViz) Rstudio Public Policy 
Sports Performance Analytics Specialization,Michigan University,Intermediate,4.5,https://in.coursera.org/specializations/sports-analytics,"Sports analytics has emerged as a field of research with increasing popularity propelled, in part, by the real-world success illustrated by the best-selling book and motion picture, Moneyball. Analysis of team and player performance data has continued to revolutionize the sports industry on the field, court, and ice as well as in living rooms among fantasy sports players and online sports gambling. 

Drawing from real data sets in Major League Baseball (MLB), the National Basketball Association (NBA), the National Hockey League (NHL), the English Premier League (EPL-soccer), and the Indian Premier League (IPL-cricket), you’ll learn how to construct predictive models to anticipate team and player performance. You’ll also replicate the success of Moneyball using real statistical models, use the Linear Probability Model (LPM) to anticipate categorical outcomes variables in sports contests, explore how teams collect and organize an athlete’s performance data with wearable technologies, and how to apply machine learning in a sports analytics context. 

This  introduction to the field of sports analytics is designed for sports managers, coaches, physical therapists, as well as sports fans who want to understand the science behind athlete performance and game prediction. New Python programmers and data analysts who are looking for a fun and practical way to apply their Python, statistics, or predictive modeling skills will enjoy exploring courses in this series.",Sports Analytics Wearable Technologies 
"Foundations of Sports Analytics: Data, Representation, and Models in Sports",Michigan University,Intermediate,4.4,https://in.coursera.org/learn/foundations-sports-analytics,"This course provides an introduction to using Python to analyze team performance in sports. Learners will discover a variety of techniques that can be used to represent sports data and how to extract narratives based on these analytical techniques. The main focus of the introduction will be on the use of regression analysis to analyze team and player performance data, using examples drawn from the National Football League (NFL), the National Basketball Association (NBA), the National Hockey League (NHL), the English Premier LEague (EPL, soccer) and the Indian Premier League (IPL, cricket). 

This course does not simply explain methods and techniques, it enables the learner to apply them to sports datasets of interest so that they can generate their own results, rather than relying on the data processing performed by others.  As a consequence the learning will be empowered to explore their own ideas about sports team performance, test them out using the data, and so become a producer of sports analytics rather than a consumer.

While the course materials have been developed using Python, code has also been produced to derive all of the results in R, for those who prefer that environment.",Performance in Sport
Introduction to Designing Data Lakes on AWS,AWS,Intermediate,4.6,https://in.coursera.org/learn/introduction-to-designing-data-lakes-in-aws,"In this class, Introduction to Designing Data Lakes on AWS, we will help you understand how to create and operate a data lake in a secure and scalable way, without previous knowledge of data science! Starting with the ""WHY"" you may want a data lake, we will look at the Data-Lake value proposition, characteristics and components.

Designing a data lake is challenging because of the scale and growth of data. Developers need to understand best practices to avoid common mistakes that could be hard to rectify. In this course we will cover the foundations of what a Data Lake is, how to ingest and organize data into the Data Lake, and dive into the data processing that can be done to optimize performance and costs when consuming the data at scale. This course is for professionals (Architects, System Administrators and DevOps) who need to design and build an architecture for secure and scalable Data Lake components. Students will learn about the use cases for a Data Lake and, contrast that with a traditional infrastructure of servers and storage.",Data Science Analytics Big Data Data Lake Amazon Web Services (Amazon AWS)
Measuring Total Data Quality,Michigan University,Beginner,Not available,https://in.coursera.org/learn/measuring-total-data-quality,"By the end of this second course in the Total Data Quality Specialization, learners will be able to:

1. Learn various metrics for evaluating Total Data Quality (TDQ) at each stage of the TDQ framework.
2. Create a quality concept map that tracks relevant aspects of TDQ from a particular application or data source.
3. Think through relative trade-offs between quality aspects, relative costs and practical constraints imposed by a particular project or study.
4. Identify relevant software and related tools for computing the various metrics.
5. Understand metrics that can be computed for both designed and found/organic data.
6. Apply the metrics to real data and interpret their resulting values from a TDQ perspective.

This specialization as a whole aims to explore the Total Data Quality framework in depth and provide learners with more information about the detailed evaluation of total data quality that needs to happen prior to data analysis. The goal is for learners to incorporate evaluations of data quality into their process as a critical component for all projects. We sincerely hope to disseminate knowledge about total data quality to all learners, such as data scientists and quantitative analysts, who have not had sufficient training in the initial steps of the data science process that focus on data collection and evaluation of data quality. We feel that extensive knowledge of data science techniques and statistical analysis procedures will not help a quantitative research study if the data collected/gathered are not of sufficiently high quality.

This specialization will focus on the essential first steps in any type of scientific investigation using data: either generating or gathering data, understanding where the data come from, evaluating the quality of the data, and taking steps to maximize the quality of the data prior to performing any kind of statistical analysis or applying data science techniques to answer research questions. Given this focus, there will be little material on the analysis of data, which is covered in myriad existing Coursera specializations. The primary focus of this specialization will be on understanding and maximizing data quality prior to analysis.",Total Data Quality (TDQ) 
SQL for Data Science,University of California,Beginner,4.6,https://in.coursera.org/learn/sql-for-data-science,"As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. This is a data scientist, “part mathematician, part computer scientist, and part trend spotter” (SAS Institute, Inc.). According to Glassdoor, being a data scientist is the best job in America; with a median base salary of $110,000 and thousands of job openings at a time. The skills necessary to be a good data scientist include being able to retrieve and work with data, and to do that you need to be well versed in SQL, the standard language for communicating with database systems.

This course is designed to give you a primer in the fundamentals of SQL and working with data so that you can begin analyzing it for data science purposes. You will begin to ask the right questions and come up with good answers to deliver valuable insights for your organization. This course starts with the basics and assumes you do not have any knowledge or skills in SQL. It will build on that foundation and gradually have you write both simple and complex queries to help you select data from tables.  You'll start to work with different types of data like strings and numbers and discuss methods to filter and pare down your results. 

You will create new tables and be able to move data into them. You will learn common operators and how to combine the data. You will use case statements and concepts like data governance and profiling. You will discuss topics on data, and practice using real-world programming assignments. You will interpret the structure, meaning, and relationships in source data and use SQL as a professional to shape your data for targeted analysis purposes. 

Although we do not have any specific prerequisites or software requirements to take this course, a simple text editor is recommended for the final project. So what are you waiting for? This is your first step in landing a job in the best occupation in the US and soon the world!",Data Science Data Analysis Sqlite SQL
IBM Data Engineering Professional Certificate,IBM,Beginner,4.6,https://in.coursera.org/professional-certificates/ibm-data-engineer,"This Professional Certificate is for anyone who wants to develop job-ready skills, tools, and a portfolio for an entry-level data engineer position. Throughout the self-paced online courses, you will immerse yourself in the role of a data engineer and acquire the essential skills you need to work with a range of tools and databases to design, deploy, and manage structured and unstructured data.  

By the end of this Professional Certificate, you will be able to explain and perform the key tasks required in a data engineering role. You will use the Python programming language and Linux/UNIX shell scripts to extract, transform and load (ETL) data. You will work with Relational Databases (RDBMS) and query data using SQL statements. You will use NoSQL databases and unstructured data.  You will be introduced to Big Data and work with Big Data engines like Hadoop and Spark.  You will gain experience with creating Data Warehouses and utilize Business Intelligence tools to analyze and extract insights.   

This program does not require any prior data engineering, or programming experience.  

This program is ACE® recommended—when you complete, you can earn up to 12 college credits.  ",Relational Database Management Syste (RDBMS) ETL & Data Pipelines NoSQL and Big Data Apache Spark SQL Data Science Database (DBMS) NoSQL Python Programming Data Analysis Pandas  Numpy
Meta Back-End Developer Professional Certificate,Meta,Beginner,4.7,https://in.coursera.org/professional-certificates/meta-back-end-developer,"Ready to gain new skills and learn the tools developers use to create websites and web applications? This 10-course program, designed by the software engineering experts at  Meta, will prepare you for an entry-level career as a back-end developer. 

On completion, you’ll get access to the Meta Career Programs Job Board—a job search platform that connects you with 200+ employers who have committed to sourcing talent through Meta’s certificate programs, as well as career support resources to help you with your job search.

In this program, you’ll learn:

Python Syntax—the most popular choice for machine learning, data science and artificial intelligence.

In-demand programming skills and how to confidently use code to solve problems. 

Linux commands and Git repositories to implement version control.

The world of data storage and databases using MySQL, and how to craft sophisticated SQL queries. 

Django web framework and how the front-end consumes data from the REST APIs. 

How to prepare for technical interviews for back-end developer roles.

Any third-party trademarks and other intellectual property (including logos and icons) referenced in the learning experience remain the property of their respective owners. Unless specifically identified as such, Coursera’s use of third-party intellectual property does not indicate any relationship, sponsorship, or endorsement between Coursera and the owners of these trademarks or other intellectual property.",Cloud Hosting Application Programming Interfaces (API) Python Programming Data Structure Computer Programming Django (Web Framework) Linux Web Development Bash (Unix Shell) Github Version Control MySQL
Attract and Engage Customers with Digital Marketing,Google,Beginner,4.8,https://in.coursera.org/learn/attract-and-engage-customers,"Attract and Engage Customers with Digital Marketing is the second of seven courses in the Google Digital Marketing & E-commerce Certificate. In this course you will practice using search engine optimization (SEO), search engine marketing (SEM), and display advertising to attract and engage customers online. You will explore the stages of the marketing funnel and learn how to use digital marketing tactics to move customers through the stages. You’ll learn how to increase the quality and quantity of website traffic by understanding SEO fundamentals like keyword research, search engine algorithms, and link building. You will also learn about paid search and advertising, and explore tactics used to gain visibility and reach potential customers on search engine results pages, or SERPs. By the end of this course you’ll be able to apply digital marketing strategies, best practices, and tools to increase awareness of a business, understand customer needs, and engage people's interests with products and services. 

Google employees who currently work in the field will guide you, providing hands-on activities and examples that simulate common digital marketing and e-commerce tasks while showing you some of the best tools and resources used on the job. 

Learners who complete the seven courses in this program will be equipped to apply for entry-level jobs in digital marketing and e-commerce. No previous experience is necessary.

By the end of this course, you will be able to do the following: 
- Identify customer personas and build your target audience
- Describe the marketing funnel’s purpose and benefits
- Know how to increase your conversion rate
- Explain the purpose of SEO and the essential SEO terms to know
- Use Google Search Console and its reports to monitor a site’s presence in Google Search results
- Recognize the benefits of SEM and why to do it
- Understand the fundamentals of Google Ads and targeting audiences",Website Structure Customer Awareness Google Search Engine Marketing Search Engine Optimization (SEO)
Satisfaction Guaranteed: Develop Customer Loyalty Online,Google,Beginner,4.8,https://in.coursera.org/learn/satisfaction-guaranteed,"You made it! Satisfaction Guaranteed: Develop Customer Loyalty Online is the seventh and final course in the Google Digital Marketing & E-commerce Certificate. In this course, you’ll explore strategies for building customer loyalty in e-commerce. You’ll also explore specific tools to develop and maintain client relationships. At the end of the course you’ll work through a scenario that demonstrates your ability to deliver a successful e-commerce strategy. Finally, you’ll wrap up the course by building professional development skills. We encourage you to complete courses 1–6 before beginning this course because they provide the foundation necessary to complete the activities at the end of this course. 

Google employees who currently work in the field will guide you, providing hands-on activities and examples that simulate common digital marketing and e-commerce tasks while showing you some of the best tools and resources used on the job.

Learners who complete the seven courses in this program will be prepared to apply for entry-level jobs in digital marketing and e-commerce. No previous experience is necessary.

By the end of this course, you will be able to do the following: 
- Identify common strategies for building customer loyalty in e-commerce
- Understand how to successfully manage client relationships and measure satisfaction
- Monitor an e-commerce store’s performance
- Update an e-commerce store based on data 
- Complete a portfolio scenario to prepare for job interviews
- Find, apply for, and prepare for interviews and jobs
- Put together a portfolio and/or resume to present to employers",Job preparedness Customer Relationship Management (CRM) Portfolio preparation E-commerce store optimization Building customer loyalty
Think Outside the Inbox: Email Marketing,Google,Beginner,4.7,https://in.coursera.org/learn/think-outside-the-inbox,"Think Outside the Inbox: Email Marketing is the fourth of seven courses in the Google Digital Marketing & E-commerce Certificate. This course will explore how to execute a successful email marketing campaign. Email marketing is one of the oldest and most proven digital marketing channels, and it is an essential component of an overall digital marketing strategy. Email is a primary channel for many businesses in reaching existing customers, encouraging interaction with the business, driving purchases, and building loyalty. In this course, you’ll explore email marketing and cover topics like: creating an email marketing strategy, executing email campaigns, and measuring the results of those campaigns. You’ll also learn how to use mailing lists and utilize automation and workflows.

Google employees who currently work in the field will guide you, providing hands-on activities and examples that simulate common digital marketing and e-commerce tasks while showing you some of the best tools and resources used on the job.

Learners who complete the seven courses in this program will be equipped to apply for entry-level jobs in digital marketing and e-commerce. No previous experience is necessary.

By the end of this course, you will be able to do the following: 
- Write effective preview text and subject lines using best practices
- Create email marketing automation and workflows
- Build and maintain email lists
- Write effective email copy
- Conduct contact management and list segmentation
- Employ best practices to handle personally identifiable information, or PII, and user data safely
- Measure and analyze email campaign results",Email Writing Email list segmentation Email marketing strategy Email marketing analytics Contact management
Modern Application Development with Python on AWS Specialization,AWS,Beginner,4.7,https://in.coursera.org/specializations/aws-python-serverless-development,"This specialization is designed to help you master the skills of designing and building cloud-native applications on AWS. We begin with the foundational technical and cloud knowledge that you need to have to build in the AWS Cloud. In the first course, you will be introduced to several AWS compute services, different storage and database offerings that AWS provides, AWS’ networking capabilities, monitoring capabilities and the AWS IAM service. 

The second course of the specialization explores how to build an API driven application using Amazon API Gateway for serverless API hosting, AWS Lambda for serverless computing and Amazon Cognito for serverless authentication. 

Modern applications require a modern database. Hence, the third course introduces you to NoSQL databases and the challenges they solve. We will dive deep into Amazon DynamoDB topics such as recovery, SDKs, partition keys, security and encryption, global tables, stateless applications, streams, and best practices. DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale.

Finally, you’ll learn how to use Amazon CodeGuru Reviewer to detect issues and identify recommendations to improve the quality and security of your code.

Note: There are 4 versions of this specialization. We recommend you choose the Specialization based on your programming language or platform of choice: Java, .NET, Node.js & Python.",Amazon Dynamodb Cloud Computing Architecture Serverless Computing Application development AWS Identity and Access Management Networking on AWS AWS Management Console Cloud Computing Aws security NoSQL Database Cryptography Workload
Assess for Success: Marketing Analytics and Measurement,Google,Beginner,4.6,https://in.coursera.org/learn/assess-for-success,"Assess for Success: Marketing Analytics and Measurement is the fifth of seven courses in the Google Digital Marketing & E-commerce Certificate. This course explores marketing analytics practices and tools. Digital marketing and e-commerce professionals are expected to analyze data from various sources (such as web pages, digital marketing channels, and e-commerce sites) and use them to gain customer insights. You’ll create media plans and set performance goals. You’ll learn how to measure, manage, and analyze data from marketing campaigns using Google Analytics, Google Ads, and similar tools. Then, learn how to adjust a marketing budget according to insights extracted from key metrics. You’ll use A/B test results to optimize a campaign and identify metrics that define a campaign's success. You will be able to analyze and visualize data and insights in spreadsheets and prepare presentations to share campaign progress or results with stakeholders. 

Google employees who currently work in the field will guide you, providing hands-on activities and examples that simulate common digital marketing and e-commerce tasks, while showing you some of the best tools and resources used on the job.

Learners who complete the seven courses in this program will be equipped to apply for entry-level jobs in digital marketing and e-commerce. No previous experience is necessary.

By the end of this course, you will be able to do the following: 
- Plan and allocate the spending of marketing budgets
- Describe the unique role of performance goals and key performance indicators (KPIs) in marketing campaigns
- Describe how tools like Google Analytics and Google Ads are used to measure website and ad campaign performance
- Describe how to determine the return on investment (ROI) or return on ad spend (ROAS) of a marketing project
- Prepare, conduct, and analyze the results from an A/B test to optimize a marketing campaign
- Apply spreadsheet features like sorting, filtering, and pivot tables to prepare data to be shared
- Create charts in spreadsheets for visualization of metrics",Digital marketing KPIs Spreadsheet management Presenting to stakeholders Media planning and strategies Marketing Analytics
Foundations of Digital Marketing and E-commerce,Google,Beginner,4.8,https://in.coursera.org/learn/foundations-of-digital-marketing-and-e-commerce,"This is the first of seven courses in the Google Digital Marketing & E-commerce Certificate, which will equip you with the skills you need to apply to entry-level roles in these fields. People who work in digital marketing and e-commerce help their organizations attract new customers, engage customers through various digital channels, and drive transactions like purchases and customer loyalty. In this course, you’ll explore entry-level jobs in digital marketing and e-commerce and identify the roles and functions that those jobs play within an organization. You’ll also learn about the marketing funnel and how it shapes the customer journey. 

Google employees who currently work in the field will guide you, providing hands-on activities and examples that simulate common digital marketing and e-commerce tasks, and helping you build your skills and prepare for the job. 

Learners who complete the seven courses in this program will be equipped to apply for entry-level jobs in digital marketing and e-commerce. No previous experience is necessary.

By the end of this course, you will be able to do the following: 
- Define the fields of digital marketing and e-commerce
- Describe the job responsibilities of an entry-level digital marketing coordinator and e-commerce analyst (and similar job titles) 
- Summarize how this program will help prepare you for a career in digital marketing and e-commerce
- Identify the roles and functions that digital marketing and e-commerce play within an organization
- Understand the customer journey and the function of journey maps
- Explain the concept of a marketing funnel
- Understand the elements and goals of a digital marketing and e-commerce strategy",Marketing Customer loyalty E-Commerce Marketing Analytics Customer Outreach
From Likes to Leads: Interact with Customers Online,Google,Beginner,4.8,https://in.coursera.org/learn/from-likes-to-leads,"From Likes to Leads: Interact with Customers Online is the third of seven courses in the Google Digital Marketing & E-commerce Certificate. This course will help you develop social media marketing strategies. Social media is a key digital marketing channel for many businesses because of the large number of people who use social platforms to socialize, interact with businesses, and share content. No digital marketing strategy is complete without an online brand presence where customers can engage with a brand. In this course you’ll explore social media platforms and identify which platform is the most appropriate for specific business needs. You’ll learn how to create content for social media using graphic design principles for marketers and learn how to manage a social media presence. In addition you’ll set goals and success metrics for social media ads. 

Google employees who currently work in the field will guide you, providing hands-on activities and examples that simulate common digital marketing and e-commerce tasks while showing you some of the best tools and resources used on the job. 

Learners who complete the seven courses in this program will be equipped to apply for entry-level jobs in digital marketing and e-commerce. No previous experience is necessary.

By the end of this course, you will be able to do the following: 
- Identify the five core pillars of social media marketing: strategy, planning and publishing, listening and engagement, analytics and reporting, and advertising
- Determine how to choose social media platforms for a campaign
- Understand how to boost engagement on social media
- Learn how to write, design, and repurpose engaging content for social media
- Recognize how to use the data gathered from social media analytics as a decision-making tool
- Learn best practices for presenting a social media report
- Achieve specific marketing goals through the use of paid social media",Social Listening Social Media Bidding Customer Engagement Social Media Analytics Social Media Branding
Teaching Impacts of Technology in K-12 Education Specialization,UC San Diego,Beginner,4.8,https://in.coursera.org/specializations/teach-impacts-technology-k12-education,"2% That’s the estimate of how many high school students in all of California took a Computer Science class in 2015. And yet, computers and data are everywhere. Just consider a typical 24 hours in your life … how many different computer devices do you use? We all live in multiple digital worlds that are changing rapidly with new apps, devices, and data analyses offering a constant stream of innovations and technology integrations for our lives.

As it's an integral part of our lives, we’re working towards computer science for all - making it possible for every student, every future member of society, to understand computing and technology. To do so, we need teachers. Teachers prepared to both teach computational concepts and use best practices so kids enjoy and see they can be successful in computer science. This is where you (and this Specialization) come in!

In this Specialization you will both learn about the impacts of computing in our world and how to teach these impacts to K-12 students. We offer both the technical knowledge and also the pedagogical approaches for teaching these concepts. Along the way you’ll engage with freely available materials you can use in your own classroom, as well as learn from teachers currently teaching these concepts in their classrooms.", Impacts of computing
